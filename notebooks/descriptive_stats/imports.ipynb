{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and utility functions. Use in other notebooks, e.g.:\n",
    "\n",
    "```\n",
    "%run imports.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if 'docker_image' in os.environ:\n",
    "    print('docker image:', os.environ['docker_image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook customisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".container {\n",
       "    width: 100%;\n",
       "}\n",
       "#maintoolbar {\n",
       "    display: none;\n",
       "}\n",
       "#header-container {\n",
       "    display: none;\n",
       "}\n",
       "#notebook {\n",
       "    padding-top: 0;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style type=\"text/css\">\n",
    ".container {\n",
    "    width: 100%;\n",
    "}\n",
    "#maintoolbar {\n",
    "    display: none;\n",
    "}\n",
    "#header-container {\n",
    "    display: none;\n",
    "}\n",
    "#notebook {\n",
    "    padding-top: 0;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# python standard library\n",
    "import sys\n",
    "import os\n",
    "import operator\n",
    "import itertools\n",
    "import collections\n",
    "import functools\n",
    "import glob\n",
    "import csv\n",
    "import datetime\n",
    "import bisect\n",
    "import sqlite3\n",
    "import subprocess\n",
    "import random\n",
    "import gc\n",
    "import shutil\n",
    "import shelve\n",
    "import contextlib\n",
    "import tempfile\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# general purpose third party packages\n",
    "\n",
    "import cython\n",
    "%reload_ext Cython\n",
    "\n",
    "import numpy as np\n",
    "nnz = np.count_nonzero\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import scipy.spatial.distance\n",
    "import numexpr\n",
    "import h5py\n",
    "import tables\n",
    "import bcolz\n",
    "import dask\n",
    "import dask.array as da\n",
    "import zarr\n",
    "import pandas\n",
    "import IPython\n",
    "from IPython.display import clear_output, display, HTML\n",
    "import rpy2\n",
    "# import rpy2.robjects as ro\n",
    "# %reload_ext rpy2.ipython\n",
    "import statsmodels\n",
    "import sklearn\n",
    "import sklearn.decomposition\n",
    "import sklearn.manifold\n",
    "import sh\n",
    "import sqlalchemy\n",
    "import pymysql\n",
    "import psycopg2\n",
    "import petl as etl\n",
    "etl.config.display_index_header = True\n",
    "import humanize\n",
    "from humanize import naturalsize, intcomma, intword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def showwarning(message, category, filename, lineno, file=None, line=None):\n",
    "    # ignore this one from matplotlib\n",
    "    if str(message).startswith('axes.color_cycle'):\n",
    "        return\n",
    "    warnings.formatwarning(message, category, filename, lineno, file=file, line=line)\n",
    "\n",
    "warnings.showwarning = showwarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plotting setup\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib_venn as venn\n",
    "import seaborn as sns\n",
    "sns.set_context('paper')\n",
    "sns.set_style('white')\n",
    "sns.set_style('ticks')\n",
    "rcParams = plt.rcParams\n",
    "rcParams['font.size'] = 8\n",
    "rcParams['axes.labelsize'] = 8\n",
    "rcParams['xtick.labelsize'] = 8\n",
    "rcParams['ytick.labelsize'] = 8\n",
    "rcParams['legend.fontsize'] = 8\n",
    "rcParams['axes.linewidth'] = .5\n",
    "rcParams['lines.linewidth'] = .5\n",
    "rcParams['patch.linewidth'] = .5\n",
    "# rcParams['font.family'] = 'arial'\n",
    "rcParams['ytick.direction'] = 'out'\n",
    "rcParams['xtick.direction'] = 'out'\n",
    "rcParams['savefig.jpeg_quality'] = 100\n",
    "rcParams['savefig.dpi'] = 120\n",
    "rcParams['lines.markeredgewidth'] = .5\n",
    "rcParams['figure.figsize'] = (4.85, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bio third party packages\n",
    "import Bio\n",
    "import pyfasta\n",
    "import pysam\n",
    "# currently broken\n",
    "# import pysamstats\n",
    "import petlx\n",
    "import petlx.bio\n",
    "import vcf\n",
    "import vcfnp\n",
    "import anhima\n",
    "import allel\n",
    "try:\n",
    "    import ete3\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_slog_indent = -2\n",
    "\n",
    "def log(*msg):\n",
    "    s = ' '.join(map(str, msg))\n",
    "    print(s, file=sys.stdout)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def timer(*msg):\n",
    "    before = datetime.datetime.now()\n",
    "    try:\n",
    "        yield\n",
    "    except:\n",
    "        after = datetime.datetime.now()\n",
    "        elapsed = (after - before).total_seconds()\n",
    "        done = 'errored after %s' % humanize.naturaldelta(elapsed)\n",
    "        if not msg:\n",
    "            msg = done\n",
    "        else:\n",
    "            msg = ', '.join(map(str, msg)) + ', ' + done\n",
    "        print(msg, file=sys.stderr)\n",
    "        sys.stderr.flush()   \n",
    "        raise\n",
    "    else:\n",
    "        after = datetime.datetime.now()\n",
    "        elapsed = (after - before).total_seconds()\n",
    "        done = 'done in %s' % humanize.naturaldelta(elapsed)\n",
    "        if not msg:\n",
    "            msg = done\n",
    "        else:\n",
    "            msg = ', '.join(map(str, msg)) + ', ' + done\n",
    "        print(msg, file=sys.stdout)\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        \n",
    "@contextlib.contextmanager\n",
    "def section(*title):\n",
    "    global _slog_indent\n",
    "    before = datetime.datetime.now()\n",
    "    _slog_indent += 2                  \n",
    "    prefix = (' ' * _slog_indent) + '[' + ', '.join(map(str, title)) + '] '\n",
    "    \n",
    "    def slog(*msg, file=sys.stdout):\n",
    "        print(prefix + ' '.join(map(str, msg)), file=file)\n",
    "        file.flush()\n",
    "    \n",
    "    slog('begin')\n",
    "                            \n",
    "    try:\n",
    "        yield slog\n",
    "    \n",
    "    except:\n",
    "        after = datetime.datetime.now()\n",
    "        elapsed = (after - before).total_seconds()\n",
    "        msg = 'errored after %s' % humanize.naturaldelta(elapsed)\n",
    "        slog(msg, file=sys.stderr)\n",
    "        _slog_indent -= 2                  \n",
    "        raise\n",
    "    \n",
    "    else:\n",
    "        after = datetime.datetime.now()\n",
    "        elapsed = (after - before).total_seconds()\n",
    "        msg = 'done in %s' % humanize.naturaldelta(elapsed)\n",
    "        slog(msg, file=sys.stdout)\n",
    "        _slog_indent -= 2                  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# not needed any more, use allel.util.hdf5_cache()\n",
    "\n",
    "# def cache_hdf5(path, *names, **h5dcreate_kwargs):\n",
    "#     assert len(names) > 0, 'provide dataset names'\n",
    "#     for n in names:\n",
    "#         assert isinstance(n, str), 'dataset names must be strings'\n",
    "#     h5dcreate_kwargs.setdefault('chunks', True)\n",
    "#     h5dcreate_kwargs.setdefault('compression', 'gzip')\n",
    "#     def decorator(f):\n",
    "#         def wrapper(*args, **kwargs):\n",
    "#             result = None\n",
    "\n",
    "#             # be verbose\n",
    "#             verbose = kwargs.pop('verbose', True)\n",
    "#             # don't repeat yourself\n",
    "#             dry = kwargs.pop('dry', True)\n",
    "#             # skip loading if cached\n",
    "#             skip = kwargs.pop('skip', False)\n",
    "            \n",
    "#             # normalise arguments to strings\n",
    "#             allargs = list(args) + [kwargs[k] for k in sorted(kwargs.keys())]\n",
    "#             strargs = [str(a) if not isinstance(a, tuple) else '_'.join(map(str, a))\n",
    "#                        for a in allargs]\n",
    "#             strargs = [a.replace('/', '_') for a in strargs]\n",
    "            \n",
    "#             # group name\n",
    "#             grp = '/'.join(strargs)\n",
    "            \n",
    "#             with h5py.File(path, mode='a') as h5f:\n",
    "#                 h5g = h5f.require_group(grp)\n",
    "                \n",
    "#                 if dry and '__success__' in h5g.attrs:\n",
    "#                     # no need to build\n",
    "#                     if skip:\n",
    "#                         if verbose:\n",
    "#                             log('@cache_hdf5', f.__name__, 'skipping', grp)\n",
    "#                     else:\n",
    "#                         if verbose:\n",
    "#                             log('@cache_hdf5', f.__name__, 'loading', grp)\n",
    "#                         if len(names) == 1:\n",
    "#                             result = h5g[names[0]][:]\n",
    "#                         else:\n",
    "#                             result = [h5g[n][:] for n in names]\n",
    "                        \n",
    "#                 else:\n",
    "#                     # need to build\n",
    "#                     if verbose:\n",
    "#                         log('@cache_hdf5', f.__name__, 'building', grp)\n",
    "                    \n",
    "#                     # reset success mark if present\n",
    "#                     if '__success__' in h5g.attrs:\n",
    "#                         del h5g.attrs['__success__']\n",
    "                        \n",
    "#                     # compute result\n",
    "#                     result = f(*args, **kwargs)\n",
    "                    \n",
    "#                     if len(names) == 1:\n",
    "#                         n = names[0]\n",
    "#                         if n in h5g:\n",
    "#                             del h5g[n]\n",
    "#                         h5g.create_dataset(n, data=result, **h5dcreate_kwargs)\n",
    "#                     else:\n",
    "#                         for n, r in zip(names, result):\n",
    "#                             if n in h5g:\n",
    "#                                 del h5g[n]\n",
    "#                             h5g.create_dataset(n, data=r, **h5dcreate_kwargs)\n",
    "                            \n",
    "#                     # mark success\n",
    "#                     h5g.attrs['__success__'] = True\n",
    "\n",
    "#             return result\n",
    "#         return wrapper\n",
    "#     return decorator\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# not needed any more, use allel.util.hdf5_cache()\n",
    "\n",
    "# def cache_hdf5_multi(path, *names, **h5dcreate_kwargs):\n",
    "#     assert len(names) > 0, 'provide dataset names'\n",
    "#     for n in names:\n",
    "#         assert isinstance(n, str), 'dataset names must be strings'\n",
    "#     h5dcreate_kwargs.setdefault('chunks', True)\n",
    "#     h5dcreate_kwargs.setdefault('compression', 'gzip')\n",
    "#     def decorator(f):\n",
    "#         def wrapper(*args, **kwargs):\n",
    "#             result = None\n",
    "\n",
    "#             # be verbose\n",
    "#             verbose = kwargs.pop('verbose', True)\n",
    "#             # don't repeat yourself\n",
    "#             dry = kwargs.pop('dry', True)\n",
    "#             # skip loading if cached\n",
    "#             skip = kwargs.pop('skip', False)\n",
    "            \n",
    "#             # normalise arguments to strings\n",
    "#             allargs = list(args) + [kwargs[k] for k in sorted(kwargs.keys())]\n",
    "#             strargs = [str(a) if not isinstance(a, tuple) else '_'.join(map(str, a))\n",
    "#                        for a in allargs]\n",
    "#             strargs = [a.replace('/', '_') for a in strargs]\n",
    "            \n",
    "#             # group name - include decorated function name so same file can be used for multiple functions\n",
    "#             grp = '/'.join([f.__name__] + strargs)\n",
    "            \n",
    "#             with h5py.File(path, mode='a') as h5f:\n",
    "#                 h5g = h5f.require_group(grp)\n",
    "                \n",
    "#                 if dry and '__success__' in h5g.attrs:\n",
    "#                     # no need to build\n",
    "#                     if skip:\n",
    "#                         if verbose:\n",
    "#                             log('@cache_hdf5', f.__name__, 'skipping', grp)\n",
    "#                     else:\n",
    "#                         if verbose:\n",
    "#                             log('@cache_hdf5', f.__name__, 'loading', grp)\n",
    "#                         if len(names) == 1:\n",
    "#                             result = h5g[names[0]][:]\n",
    "#                         else:\n",
    "#                             result = [h5g[n][:] for n in names]\n",
    "                        \n",
    "#                 else:\n",
    "#                     # need to build\n",
    "#                     if verbose:\n",
    "#                         log('@cache_hdf5', f.__name__, 'building', grp)\n",
    "                    \n",
    "#                     # reset success mark if present\n",
    "#                     if '__success__' in h5g.attrs:\n",
    "#                         del h5g.attrs['__success__']\n",
    "                        \n",
    "#                     # compute result\n",
    "#                     result = f(*args, **kwargs)\n",
    "                    \n",
    "#                     if len(names) == 1:\n",
    "#                         n = names[0]\n",
    "#                         if n in h5g:\n",
    "#                             del h5g[n]\n",
    "#                         h5g.create_dataset(n, data=result, **h5dcreate_kwargs)\n",
    "#                     else:\n",
    "#                         for n, r in zip(names, result):\n",
    "#                             if n in h5g:\n",
    "#                                 del h5g[n]\n",
    "#                             h5g.create_dataset(n, data=r, **h5dcreate_kwargs)\n",
    "                            \n",
    "#                     # mark success\n",
    "#                     h5g.attrs['__success__'] = True\n",
    "\n",
    "#             return result\n",
    "#         return wrapper\n",
    "#     return decorator\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autosomes = '2R', '2L', '3R', '3L'\n",
    "chromosomes = autosomes + ('X',)\n",
    "\n",
    "\n",
    "class GenomeFigure(object):\n",
    "    \n",
    "    def __init__(self, genome, *args, **kwargs):\n",
    "        self.chromosomes = kwargs.pop('chromosomes', ['2R', '2L', '3R', '3L', 'X'])\n",
    "        maxchrsize = max(np.array(genome[chrom]).size for chrom in self.chromosomes)\n",
    "        fig = plt.figure(*args, **kwargs)\n",
    "        self.fig = fig\n",
    "        self.ax = dict()\n",
    "        for i, chrom in enumerate(self.chromosomes):\n",
    "            ax = fig.add_subplot(3, 2, i+1)\n",
    "            self.ax[chrom] = ax\n",
    "            S = np.array(genome[chrom])\n",
    "            if i % 2 == 1:\n",
    "                sns.despine(ax=ax, offset=10, top=True, left=True, right=False)\n",
    "                ax.set_xlim(0, maxchrsize)\n",
    "                ax.yaxis.tick_right()\n",
    "                ax.yaxis.set_label_position('right')\n",
    "            else:\n",
    "                ax.set_xlim((S.size)-(maxchrsize), S.size)\n",
    "                ax.yaxis.tick_left()\n",
    "                sns.despine(ax=ax, offset=10, top=True, left=False, right=True)\n",
    "            ax.set_xticks(range(0, S.size, int(5e6)))\n",
    "            ax.set_xticklabels(range(0, int(S.size/1e6), 5))\n",
    "            ax.set_title(chrom, fontweight='bold')\n",
    "            ax.xaxis.tick_bottom()\n",
    "        fig.tight_layout()\n",
    "        \n",
    "    def apply(self, f, **kwargs):\n",
    "        chromosomes = kwargs.pop('chromosomes', self.chromosomes)\n",
    "        for chrom in chromosomes:\n",
    "            ax = self.ax[chrom]\n",
    "            f(chrom, ax, **kwargs)\n",
    "\n",
    "            \n",
    "def subplots(*args, despine=None, **kwargs):\n",
    "    fig, ax = plt.subplots(*args, **kwargs)\n",
    "    if despine is None:\n",
    "        despine = dict(offset=10, trim=False)\n",
    "    if hasattr(ax, '__len__'):\n",
    "        for a in ax:\n",
    "            sns.despine(ax=a, **despine)\n",
    "    else:\n",
    "        sns.despine(ax=ax, **despine)\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pip_list():\n",
    "    import pip\n",
    "    cmd = pip.commands.ListCommand()\n",
    "    cmd.main([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str_ascii(b):\n",
    "    if isinstance(b, (tuple, list)):\n",
    "        return type(b)([str(i, 'ascii') for i in b])\n",
    "    elif isinstance(b, np.ndarray):\n",
    "        return np.array([str(i, 'ascii') for i in b.flatten()]).reshape(b.shape)\n",
    "    else:\n",
    "        return str(b, 'ascii')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
